{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a lr_classifier for docs\n",
    "\n",
    "dataset: http://ai.stanford.edu/~amaas/data/sentiment/  \n",
    "tarを展開して使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "labels = {\"pos\":0, \"neg\":1}\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "for s in [\"train\",\"test\"]:\n",
    "    for l in [\"pos\",\"neg\"]:\n",
    "        path =\"./aclImdb/%s/%s\" % (s,l)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path,file),\"r\",encoding=\"utf-8\") as infile:\n",
    "                txt = infile.read()\n",
    "                df = df.append([[txt,labels[l]]],ignore_index=True)\n",
    "                pbar.update()\n",
    "df.columns = [\"review\",\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31013</th>\n",
       "      <td>I expected this to be a lot better. I love Tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46866</th>\n",
       "      <td>I have seen it a few times and get completely ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>I only saw this movie once, and that was enoug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42343</th>\n",
       "      <td>i am an avid ff7 fan, for instance i have the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>This is my first Deepa Mehta film. I saw the f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "31013  I expected this to be a lot better. I love Tim...          1\n",
       "46866  I have seen it a few times and get completely ...          0\n",
       "28326  I only saw this movie once, and that was enoug...          1\n",
       "42343  i am an avid ff7 fan, for instance i have the ...          0\n",
       "39952  This is my first Deepa Mehta film. I saw the f...          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ランダム化\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv(\"./movie_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0, 'sweet': 5, 'two': 7, 'the': 6, 'sun': 4, 'is': 1, 'weather': 8, 'one': 2, 'shining': 3}\n",
      "[[0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1]\n",
      " [2 3 2 1 1 1 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "docs = np.array([\"the sun is shining\",\"The weather is sweet\", \n",
    "                 \"the sun is shining, the weather is sweet, and one and one is two\"])\n",
    "bag = count.fit_transform(docs)\n",
    "print(count.vocabulary_)\n",
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HTMLタグおよびemorticonの処理\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub(\"<[^>]*>\",\"\",text)\n",
    "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\",text)\n",
    "    text = re.sub(\"[\\W]+\", \" \", text.lower() + \"\".join(emoticons).replace(\"-\",\"\"))\n",
    "    return text\n",
    "\n",
    "text = df.loc[30,\"review\"][-500:]\n",
    "print(text)\n",
    "print(preprocessor(text))\n",
    "df[\"review\"] = df[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize with steming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stopwords\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split_dataset\n",
    "x_train = df.loc[:25000,\"review\"].values\n",
    "y_train = df.loc[:25000,\"sentiment\"].values\n",
    "x_test  = df.loc[25000:,\"review\"].values\n",
    "y_test  = df.loc[25000:,\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "# cross_validate\n",
    "# param_grid_search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None)\n",
    "param_grid = [{\"vect__ngram_range\":[(1,1)],\n",
    "              \"vect__stop_words\":[stop,None],\n",
    "               \"vect__tokenizer\":[tokenizer,tokenizer_porter],\n",
    "               \"clf__penalty\":[\"l1\",\"l2\"],\n",
    "               \"clf__C\":[1.0,10.0,100.0]},\n",
    "               {\"vect__ngram_range\":[(1,1)],\n",
    "                \"vect__stop_words\":[stop,None],\n",
    "                \"vect__tokenizer\":[tokenizer, tokenizer_porter],\n",
    "                \"vect__use_idf\":[False],\n",
    "                \"vect__norm\":[None],\n",
    "                \"clf__penalty\":[\"l1\",\"l2\"],\n",
    "                \"clf__C\":[1.0, 10.0, 100.0]}\n",
    "              ]\n",
    "lr_tfidf = Pipeline([(\"vect\",tfidf),\n",
    "                    (\"clf\",LogisticRegression(random_state=0))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                          scoring=\"accuracy\",\n",
    "                          cv=3,verbose=2,\n",
    "                          n_jobs=2)\n",
    "gs_lr_tfidf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10.0,\n",
       " 'clf__penalty': 'l2',\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': None,\n",
       " 'vect__tokenizer': <function __main__.tokenizer>}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testSet: 0.911924741052\n"
     ]
    }
   ],
   "source": [
    "gs_lr_tfidf.best_score_\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print(\"testSet:\",clf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 大規模なデータ処理\n",
    "### オンラインアルゴリズムとアウトオブコア学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path,\"r\",encoding=\"utf-8\") as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text,label = line[:-3], int(line[-2])\n",
    "            yield text,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object stream_docs at 0x1273abbf8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_docs(path=\"./movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None,None\n",
    "    return docs,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error=\"ignore\",n_features=2**21,preprocessor=None,tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss=\"hinge\",random_state=1,n_iter=1)\n",
    "doc_stream = stream_docs(path=\"./movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:09\n"
     ]
    }
   ],
   "source": [
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.asarray([0,1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream,size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf score: 0.825\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(\"clf score:\",clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tips\n",
    " - SGDclassifierはマルチクラスに対応している\n",
    " - clf.partial_fit(X,y,classes=classes)のとき、classes paramに全てのラベルを入れ込んでおく\n",
    " - n_jobs paramで複数CPUに分割できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
